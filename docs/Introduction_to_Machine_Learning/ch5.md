# ch5 假设检验

## 1. 归纳学习假设

大部分学习涉及从具体的训练示例中获取一般概念，归纳学习算法可以很好地保证输出假设在训练数据上符合目标概念，任一假设若在**足够大**的训练样例集中**很好地逼近**目标函数，它也能在**未见实例中**很好地逼近目标函数。

- 如何估计精度？假设函数的性能如何？
- 不同的算法在训练集上得出的目标函数很容易评估优劣，那么在真实数据集上结果又会如何？
- 使用有限的数据来学习假设和估计其准确性的最佳方法是什么？

## 2. 伯努利试验

二项分布：抛硬币（正面朝上的概率 $p$，抛 $n$ 次，观察到的正面朝上 $r$ 次）

$$P(r) = \frac{n!}{r!(n-r)!}p^r(1-p)^(n-r)$$

$$E[R] = \mu = np$$

$$Var[R] = E[(R-E[R])^2] = \sigma^2 = np(1-p)$$

## 3. 如何估计精度

样本错误率为

$$error_s(h) = \frac{1}{n} \sum_{x\in S} \delta(f(x) \ne h(x)) = \frac{r}{n}$$ 

真实错误率为

$$error_D(h) = Pr_{x\in D}[f(x) \ne h(x)] = p$$

于是

$$E[r] = np, E[error_S(h)] = p = error_D(h)$$

$$\sigma_{error_S(h)} = \frac{\sigma_r}{n} = \frac{\sqrt{np(1-p)}}{n} \approx \sqrt{\frac{error_S(h)(1-error_S(h))}{n}}$$

估计偏差为 $bias = E[error_S(h)] - error_D(h)$，注意不能在训练集上验证模型，即训练集和测试集应该相互独立。尽管在无偏估计上也可能存在两个错误率不一致的情况，这时应该选择方差较小的无偏估计。

## 4. 估计值的准确性

参数 $p$ 的 $N \%$ 置信区间是一个以 $N \%$ 的概率包含 $p$ 的区间，其中 $N\%$ 为置信度。

伯努利分布较难计算置信区间，但正态分布下就很容易计算置信区间。一般情况下，当 $n>30$，$np(1-p)>5$ 时，我们可以将二项分布近似为正态分布。

于是，假设我们的置信度为 $95\%$，则置信区间可以近似为 $$error_S(h) ± 1.96\frac{\sqrt{np(1-p)}}{n} \approx \sqrt{\frac{error_S(h)(1-error_S(h))}{n}}$$

单边置信区间为 $$error_S(h) + 1.645\frac{\sqrt{np(1-p)}}{n} \approx \sqrt{\frac{error_S(h)(1-error_S(h))}{n}}$$

中心极限定理：对于任意的独立同分布（$\mu , \sigma^2$，其中方差为有限值），只要数据量足够大，那么最终该分布趋近于正态分布，均值为 $\mu$，方差为 $\sigma^2 / n$。