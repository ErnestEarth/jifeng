# ch8 无监督学习

## 1. 简介

有监督学习：研究输入数据的条件概率分布。

无监督学习：研究输入数据的联合概率分布。

半监督学习：少量输入数据是已知输出的，绝大部分数据是不知道输出的。

在无监督学习中，期望学习到没有标记的数据的结构与表示。

- 数据聚类
- 特征降维
- 边界检测
- 密度建模

**聚类**：将相似的对象放在一起，研究数据的结构。核心问题是**相似度**：类内相似度、类间相似度。

- 软聚类：一个数据点可以属于多个类
- 硬聚类：一个数据点只能属于一个类
- 层次聚类：可以聚出树的结构
- 非层次聚类：只有一层

聚类分析的应用：

- 生物学：同源基因簇
- 图像压缩
- 电子经济：消费者群体分类
- 互联网应用：事件检测、事件趋势分析、相似的访问模式

聚类分析的必要条件：

- 数据没有标签
- 对象之间存在距离或者相似度度量函数
- 聚类算法

## 2. 层次聚类

构建一棵层次聚类树，研究不同层级的数据粒度之间的关系。

方法：自底向上（凝聚式）、自顶向下（划分式）

**自底向上**：

- 初始每一个实例单独为一类
- 找到最相似的两类进行合并，重复直到只剩一个类

如何计算类间相似度：

- $\tt Single\ Linkage$：两个类间所有点的相似度最小值作为这两类的类间相似度
- $\tt Complete\ Linkage$：两个类间所有点的相似度最大值作为这两类的类间相似度
- $\tt Average\ Linkage$：两个类间所有点的相似度加权平均值作为这两类的类间相似度

层次聚类的特点：

- 优点：灵活，可以任意指定粒度；可以很方便的处理任意类型的数据；可以处理任意形式的相似度或距离
- 缺点：聚类终点比较模糊；计算时间复杂度较高

## 3. K-means 聚类和 K-medoids 聚类

K-means 聚类：

- 模型：向量空间模型
- 策略：最小化类之间的距离
- 算法：迭代算法
- 是一种硬聚类、非层次聚类
- 适合处理数据不是太稀疏的、好分离的问题；可以分离出非凸的形状；对数据噪声很敏感

K-medoids 聚类：用数据点替代数据均值作为中心进行聚类