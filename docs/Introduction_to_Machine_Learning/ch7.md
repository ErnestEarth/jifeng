# ch7 支持向量机

## 1. 背景

支持向量机用于解决分类问题。

分类方法：

- 决策树：擅长处理描述性的特征，用于学习离散目标，可以用回归的方法处理连续目标
- K 近邻算法：擅长处理数值类特征，可以用于学习离散目标和连续目标
- 支持向量机：擅长处理数值类特征，可以用于学习离散目标和连续目标

## 2. 线性支持向量机

**最大间隔分类器**：

- 间隔：边界在到达数据点之前可以增加的宽度，表示正例和反例这两个超平面到远点的距离差值

- 支持向量：训练样本中和这个超平面距离最近的样本点

    ![支持向量机](img/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA.jpg)

**对偶问题**：

- 通用问题的优化不好求解，但是对偶问题可以采用拉格朗日函数进行优化
- 需要满足 KKT 条件

**线性不可分问题**：

- 可以定义一个损失函数，对于每一个样例求出损失函数表示是否有损失
- 常用损失函数：0/1 Loss、Hinge Loss、Exponential Loss、Logistic Loss
- 在分类函数中引入松弛因子 $\epsilon$，如果 $\epsilon = 0$ 表明该点在边界上；$0 < \epsilon < 1$ 表明该点在边界内部，分类正确；如果 $\epsilon > 1$ 表明该点分类错误
- 边界描述**结构风险**，错误描述**经验风险**，我们希望边界足够大，错误足够小

## 3. 核函数支持向量机

对于线性不可分问题，另一种方法是给样例增加一个维度，将输入空间映射到一个**特征空间**，使得样例在更高维度上线性可分。

**核函数**：核函数可以直接计算隐式映射到高维特征空间后的向量内积，而不需要显式地写出映射后的结果，它虽然完成了将特征从低维到高维的转换，但最终却是在低维空间中完成向量内积计算，与高维特征空间中的计算等效**（低维计算，高维表现）**，从而避免了直接在高维空间无法计算的问题。

如何构造核函数：

- 选择一个映射函数
- 选择一个常用的核函数
- 从常用核函数构造复杂核函数